{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-23T17:53:48.690197Z","iopub.execute_input":"2022-04-23T17:53:48.691303Z","iopub.status.idle":"2022-04-23T17:53:48.712223Z","shell.execute_reply.started":"2022-04-23T17:53:48.691130Z","shell.execute_reply":"2022-04-23T17:53:48.711377Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/m5-forecasting-uncertainty/calendar.csv\n/kaggle/input/m5-forecasting-uncertainty/sample_submission.csv\n/kaggle/input/m5-forecasting-uncertainty/sell_prices.csv\n/kaggle/input/m5-forecasting-uncertainty/sales_train_validation.csv\n/kaggle/input/m5-forecasting-uncertainty/sales_train_evaluation.csv\n/kaggle/input/m5-forecasting-accuracy/calendar.csv\n/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\n/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\n/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\n/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_calendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\ndf_sell_prices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\ndf_train = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\ndf_test = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:53:49.859435Z","iopub.execute_input":"2022-04-23T17:53:49.860469Z","iopub.status.idle":"2022-04-23T17:54:03.506928Z","shell.execute_reply.started":"2022-04-23T17:53:49.860403Z","shell.execute_reply":"2022-04-23T17:54:03.506117Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from abc import ABC, abstractmethod\n\nclass Forecaster(ABC):\n    \"\"\"\n    Base predictor class. Must have a model object, a fit function and a predict function\n    \"\"\"\n    def __init__(self, model, **kwargs):\n        self.model = model\n    @abstractmethod\n    def fit(self):\n        pass\n    @abstractmethod\n    def predict(self):\n        pass","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.515815Z","iopub.execute_input":"2022-04-23T17:54:03.516055Z","iopub.status.idle":"2022-04-23T17:54:03.530944Z","shell.execute_reply.started":"2022-04-23T17:54:03.516028Z","shell.execute_reply":"2022-04-23T17:54:03.530078Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.532985Z","iopub.execute_input":"2022-04-23T17:54:03.533250Z","iopub.status.idle":"2022-04-23T17:54:03.564684Z","shell.execute_reply.started":"2022-04-23T17:54:03.533221Z","shell.execute_reply":"2022-04-23T17:54:03.563764Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n0       CA    0    0    0    0  ...       1       3       0       1       1   \n1       CA    0    0    0    0  ...       0       0       0       0       0   \n2       CA    0    0    0    0  ...       2       1       2       1       1   \n3       CA    0    0    0    0  ...       1       0       5       4       1   \n4       CA    0    0    0    0  ...       2       1       1       0       1   \n\n   d_1909  d_1910  d_1911  d_1912  d_1913  \n0       1       3       0       1       1  \n1       1       0       0       0       0  \n2       1       0       1       1       1  \n3       0       1       3       7       2  \n4       1       2       2       2       4  \n\n[5 rows x 1919 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d_1</th>\n      <th>d_2</th>\n      <th>d_3</th>\n      <th>d_4</th>\n      <th>...</th>\n      <th>d_1904</th>\n      <th>d_1905</th>\n      <th>d_1906</th>\n      <th>d_1907</th>\n      <th>d_1908</th>\n      <th>d_1909</th>\n      <th>d_1910</th>\n      <th>d_1911</th>\n      <th>d_1912</th>\n      <th>d_1913</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_validation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_validation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_validation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 1919 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_calendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.565895Z","iopub.execute_input":"2022-04-23T17:54:03.566683Z","iopub.status.idle":"2022-04-23T17:54:03.582313Z","shell.execute_reply.started":"2022-04-23T17:54:03.566642Z","shell.execute_reply":"2022-04-23T17:54:03.581399Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n\n  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n0          NaN          NaN          NaN        0        0        0  \n1          NaN          NaN          NaN        0        0        0  \n2          NaN          NaN          NaN        0        0        0  \n3          NaN          NaN          NaN        1        1        0  \n4          NaN          NaN          NaN        1        0        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>weekday</th>\n      <th>wday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>d</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>Saturday</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-30</td>\n      <td>11101</td>\n      <td>Sunday</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-31</td>\n      <td>11101</td>\n      <td>Monday</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-02-01</td>\n      <td>11101</td>\n      <td>Tuesday</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-02-02</td>\n      <td>11101</td>\n      <td>Wednesday</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testx = [1,2,3,4,5]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.583578Z","iopub.execute_input":"2022-04-23T17:54:03.583830Z","iopub.status.idle":"2022-04-23T17:54:03.588161Z","shell.execute_reply.started":"2022-04-23T17:54:03.583802Z","shell.execute_reply":"2022-04-23T17:54:03.587394Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Naive\n\n$\\hat{Y}_{n+i} = Y_{n}, i = 1,2,...,h$","metadata":{}},{"cell_type":"code","source":"def naive_model_fn(inputs: list, horizon:int=28, forecast_type:str=None):\n    value = inputs[-7:] if forecast_type == \"seasonal\" else inputs[-1:]\n    forecast = value * horizon\n    forecast = forecast[-horizon:]\n    assert len(forecast) == horizon\n    return forecast\n\nclass NaiveForecaster(Forecaster):\n    def __init__(self):\n        super().__init__(naive_model_fn)\n    def fit(self, inputs, horizon, forecast_type):\n        return self.model\n    def predict(self, inputs, horizon, forecast_type):\n        return self.model(inputs, horizon, forecast_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.589308Z","iopub.execute_input":"2022-04-23T17:54:03.589565Z","iopub.status.idle":"2022-04-23T17:54:03.599932Z","shell.execute_reply.started":"2022-04-23T17:54:03.589537Z","shell.execute_reply":"2022-04-23T17:54:03.599137Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"naive_forecaster = NaiveForecaster()\npred_naive = naive_forecaster.predict(testx, 28, None)\npred_s_naive = naive_forecaster.predict(testx, 28, \"seasonal\")\n\nprint(pred_naive)\nprint(pred_s_naive)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:54:03.601089Z","iopub.execute_input":"2022-04-23T17:54:03.601517Z","iopub.status.idle":"2022-04-23T17:54:03.611943Z","shell.execute_reply.started":"2022-04-23T17:54:03.601477Z","shell.execute_reply":"2022-04-23T17:54:03.611336Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n[3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Simple Exponential Smoothing\n\n$\\hat{Y}_{t+1} = \\alpha Y_{t} + (1-\\alpha)\\hat{Y}_{t}$ where alpha is in the range [0.1,0.3]","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n\ndef ses_fn(x: list, alpha:float, horizon=int):\n    def _update_forecast(prev_actual, prev_forecast, alpha):\n        return alpha * prev_actual + (1-alpha) * prev_forecast\n    for idx, val in enumerate(x):\n        if idx == 0:\n            forecast = val\n            prev_actual = val\n        else:\n            forecast = _update_forecast(prev_actual, forecast, alpha)\n            prev_actual = val\n    forecast = _update_forecast(prev_actual, forecast, alpha)\n    return [forecast] * horizon\n\nclass SimpleExponentialForecaster(Forecaster):\n    def __init__(self):\n        super().__init__(ses_fn)\n    def fit(self, alpha, optimized):\n        return self.model\n    def predict(self, x, alpha, horizon):\n        return self.model(x, alpha, horizon)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:23:27.801017Z","iopub.execute_input":"2022-04-23T18:23:27.801562Z","iopub.status.idle":"2022-04-23T18:23:27.807214Z","shell.execute_reply.started":"2022-04-23T18:23:27.801530Z","shell.execute_reply":"2022-04-23T18:23:27.806417Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(testx)\nses_forecaster = SimpleExponentialForecaster()\npred_ses = ses_forecaster.predict(testx, alpha=0.1, horizon=28)\nprint(pred_ses)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:24:24.825903Z","iopub.execute_input":"2022-04-23T18:24:24.826228Z","iopub.status.idle":"2022-04-23T18:24:24.833873Z","shell.execute_reply.started":"2022-04-23T18:24:24.826195Z","shell.execute_reply":"2022-04-23T18:24:24.832959Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[1, 2, 3, 4, 5]\n[1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049, 1.9049]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Moving Averages\n\n$\\hat{Y}_t = \\frac{\\sum^{k}_{i=1} Y_{t-i}}{k}$ where K is selected from the range [2,5]","metadata":{}},{"cell_type":"code","source":"def moving_averages_fn(x: list, k:int, horizon:int=28):\n    forecast = np.mean(x[-k:])\n    return [forecast] * horizon\n\nclass MovingAverageForecaster(Forecaster):\n    def __init__(self):\n        super().__init__(moving_averages_fn)\n    def fit(self):\n        return self.model\n    def predict(self, inputs, k):\n        return self.model(inputs, k)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:33:32.413045Z","iopub.execute_input":"2022-04-23T18:33:32.413395Z","iopub.status.idle":"2022-04-23T18:33:32.421252Z","shell.execute_reply.started":"2022-04-23T18:33:32.413362Z","shell.execute_reply":"2022-04-23T18:33:32.420214Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"print(testx)\nmovavg_forecaster = MovingAverageForecaster()\npred_movavg = movavg_forecaster.predict(testx, k=2)\nprint(pred_movavg)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T18:33:34.992441Z","iopub.execute_input":"2022-04-23T18:33:34.992999Z","iopub.status.idle":"2022-04-23T18:33:35.000408Z","shell.execute_reply.started":"2022-04-23T18:33:34.992951Z","shell.execute_reply":"2022-04-23T18:33:34.999376Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[1, 2, 3, 4, 5]\n[4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Croston's Method (CRO)\n$\\hat{Y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t}$\n\nWhere:\n- $\\hat{z}_t$ represents the non-zero demand size\n- $\\hat{p}_t$ represents the inter-demand intervals\n- $\\hat{z}_t$ and $\\hat{p}_t$ are predicted using simple exponential smoothing and smoothing parameters of both components are set to 0.1 and the first observation of the components are used for initialisations.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"croston_forecaster = CrostonForecaster()\npred_croston = croston_forecaster.predict(testx, threshold=3, horizon=28)\nprint(pred_croston)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny = np.array([0,0,2,7,0,0,0,-5])\nn_timepoints = len(y)\nsmoothing = 0.1\nfirst_occurrence = np.argmax(y[:n_timepoints] > 0)\n\nq, a, f = np.full((3, n_timepoints + 1), np.nan)\np = 1  # periods since last demand observation\n\nq[0] = y[first_occurrence]\na[0] = 1 + first_occurrence\nf[0] = q[0] / a[0]\n\nfor t in range(0, n_timepoints):\n    if y[t] > 0:\n        q[t + 1] = smoothing * y[t] + (1 - smoothing) * q[t]\n        a[t + 1] = smoothing * p + (1 - smoothing) * a[t]\n        f[t + 1] = q[t + 1] / a[t + 1]\n        p = 1\n    else:\n        q[t + 1] = q[t]\n        a[t + 1] = a[t]\n        f[t + 1] = f[t]\n        p += 1\n\nprint(first_occurrence)\nprint(y)\nprint(q)\nprint(a)\nprint(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aggregate-Disaggregate Intermittend Demand Approach (ADIDA)\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}